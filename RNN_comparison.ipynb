{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "import gensim as gs\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU,SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  emotion\n",
       "0  @first_timee хоть я и школота, но поверь, у на...        1\n",
       "1  Да, все-таки он немного похож на него. Но мой ...        1\n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...        1\n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...        1\n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...        1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = pd.read_csv(\"positive.csv\", header=None, error_bad_lines=False, sep=';', names = [str(x) for x in (list(range(3)) + ['Text'] + list(range(4,12)))])\n",
    "pos[\"emotion\"] = 1\n",
    "pos.drop([str(x) for x in (list(range(3)) + list(range(4,12)))], inplace=True, axis=1)\n",
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  emotion\n",
       "0  на работе был полный пиддес :| и так каждое за...        0\n",
       "1  Коллеги сидят рубятся в Urban terror, а я из-з...        0\n",
       "2  @elina_4post как говорят обещаного три года жд...        0\n",
       "3  Желаю хорошего полёта и удачной посадки,я буду...        0\n",
       "4  Обновил за каким-то лешим surf, теперь не рабо...        0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = pd.read_csv(\"negative.csv\", header=None, error_bad_lines=False, sep=';', names = [str(x) for x in (list(range(3)) + ['Text'] + list(range(4,12)))])\n",
    "neg[\"emotion\"] = 0\n",
    "neg.drop([str(x) for x in (list(range(3)) + list(range(4,12)))], inplace=True, axis=1)\n",
    "neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([neg.iloc[:2000], pos.iloc[:2000]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = re.compile('[^а-яА-ЯёЁ ]')\n",
    "df[\"cleaned\"] = df[\"Text\"].apply(lambda x:re.sub(r'\\s+', ' ', (reg.sub(' ', x))).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentenceInLemmas(sentence, m=Mystem()):\n",
    "    processed = m.analyze(sentence)\n",
    "    tagged_sentences = []\n",
    "    tagged = []\n",
    "    for w in processed:        \n",
    "        if w[\"text\"].strip() == \"+\":\n",
    "            tagged_sentences.append(\" \".join(tagged))\n",
    "            tagged = []\n",
    "            continue\n",
    "        try:\n",
    "            lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = w[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            pos = pos.split('=')[0].strip()\n",
    "            tagged.append(lemma+'_'+uTag(pos))\n",
    "        except:\n",
    "            continue\n",
    "    tagged_sentences.append(\" \".join(tagged))\n",
    "    return tagged_sentences\n",
    "\n",
    "\n",
    "def uTag(tag):\n",
    "    return {\n",
    "        'A':       'ADJ',                                                                                                                                                                                                                                                                  \n",
    "        'ADV':     'ADV',                                                                                                                                                                                                                                                                  \n",
    "        'ADVPRO':  'ADV',                                                                                                                                                                                                                                                                  \n",
    "        'ANUM':    'ADJ',                                                                                                                                                                                                                                                                    \n",
    "        'APRO':    'DET',                                                                                                                                                                                                                                                                    \n",
    "        'COM':     'ADJ',                                                                                                                                                                                                                                                                  \n",
    "        'CONJ':    'SCONJ',                                                                                                                                                                                                                                                                 \n",
    "        'INTJ':    'INTJ',                                                                                                                                                                                                                                                                 \n",
    "        'NONLEX':  'X',                                                                                                                                                                                                                                                                      \n",
    "        'NUM':     'NUM',                                                                                                                                                                                                                                                                   \n",
    "        'PART':    'PART',                                                                                                                                                                                                                                                                   \n",
    "        'PR':      'ADP',                                                                                                                                                                                                                                                                    \n",
    "        'S':       'NOUN',                                                                                                                                                                                                                                                                   \n",
    "        'SPRO':    'PRON',                                                                                                                                                                                                                                                                  \n",
    "        'UNKN':    'X',                                                                                                                                                                                                                                                                      \n",
    "        'V':       'VERB'\n",
    "    }[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = ' + '.join(df[\"cleaned\"].values)\n",
    "df[\"lemmed\"] = sentenceInLemmas(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>lemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>0</td>\n",
       "      <td>на работе был полный пиддес и так каждое закры...</td>\n",
       "      <td>на_ADP работа_NOUN быть_VERB полный_ADJ пиддес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>0</td>\n",
       "      <td>Коллеги сидят рубятся в а я из за долбанной ви...</td>\n",
       "      <td>коллега_NOUN сидеть_VERB рубиться_VERB в_ADP а...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>0</td>\n",
       "      <td>как говорят обещаного три года ждут</td>\n",
       "      <td>как_SCONJ говорить_VERB обещаной_ADJ три_NUM г...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>0</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки я буду...</td>\n",
       "      <td>желать_VERB хороший_ADJ полет_NOUN и_SCONJ уда...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>0</td>\n",
       "      <td>Обновил за каким то лешим теперь не работает п...</td>\n",
       "      <td>обновлять_VERB за_ADP какой_DET то_SCONJ леший...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  emotion  \\\n",
       "0  на работе был полный пиддес :| и так каждое за...        0   \n",
       "1  Коллеги сидят рубятся в Urban terror, а я из-з...        0   \n",
       "2  @elina_4post как говорят обещаного три года жд...        0   \n",
       "3  Желаю хорошего полёта и удачной посадки,я буду...        0   \n",
       "4  Обновил за каким-то лешим surf, теперь не рабо...        0   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  на работе был полный пиддес и так каждое закры...   \n",
       "1  Коллеги сидят рубятся в а я из за долбанной ви...   \n",
       "2                как говорят обещаного три года ждут   \n",
       "3  Желаю хорошего полёта и удачной посадки я буду...   \n",
       "4  Обновил за каким то лешим теперь не работает п...   \n",
       "\n",
       "                                              lemmed  \n",
       "0  на_ADP работа_NOUN быть_VERB полный_ADJ пиддес...  \n",
       "1  коллега_NOUN сидеть_VERB рубиться_VERB в_ADP а...  \n",
       "2  как_SCONJ говорить_VERB обещаной_ADJ три_NUM г...  \n",
       "3  желать_VERB хороший_ADJ полет_NOUN и_SCONJ уда...  \n",
       "4  обновлять_VERB за_ADP какой_DET то_SCONJ леший...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"prepared.csv\", sep=\";\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(frame, vocabsize, vocab):\n",
    "    matrixes = []\n",
    "    tone = []\n",
    "    for i in tqdm_notebook(range(frame.values.shape[0])):\n",
    "        try:\n",
    "            words = frame.iloc[i]['lemmed'].split(' ')\n",
    "            if len(words) == 0:\n",
    "                break\n",
    "            matr = np.zeros(shape=(1, vocabsize))\n",
    "            for w in words:\n",
    "                try:\n",
    "                    matr = np.vstack((matr, vocab[w]))\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if matr.shape[0] > 2:\n",
    "                matrixes.append(matr[1:matr.shape[0]][:])\n",
    "                tone.append(frame.iloc[i]['emotion'])\n",
    "        except AttributeError:\n",
    "            print(frame.iloc[i]['lemmed'])\n",
    "\n",
    "    return matrixes, tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = gs.models.KeyedVectors.load_word2vec_format('web.bin', binary=True)\n",
    "vocabsize = 300\n",
    "timesteps = 32\n",
    "batch_size = 64\n",
    "n_epochs = 200\n",
    "n_parts = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrices, tones = to_matrix(df, vocabsize, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(len(matrices))):\n",
    "    matrices[i] = np.vstack(\n",
    "        (np.random.normal(scale=0.005, size=(timesteps - matrices[i].shape[0], vocabsize)),matrices[i]))\n",
    "matrices = np.array(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(matrices, tones, test_size=0.2, random_state=42,stratify=tones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train, ndmin=2).T\n",
    "y_test = np.array(y_test, ndmin=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_rnn(timesteps, vocabsize):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(1, return_sequences=False, input_shape=(timesteps, vocabsize), dropout=0.05, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gru(timesteps, vocabsize):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(1, return_sequences=False, input_shape=(timesteps, vocabsize), dropout=0.05, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm(timesteps, vocabsize):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(1, return_sequences=False, input_shape=(timesteps, vocabsize), dropout=0.05, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = simple_rnn(timesteps, vocabsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3055 samples, validate on 764 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.7248 - acc: 0.4985 - val_loss: 0.7099 - val_acc: 0.4987\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.7013 - acc: 0.5087 - val_loss: 0.6949 - val_acc: 0.5380\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.6905 - acc: 0.5342 - val_loss: 0.6881 - val_acc: 0.5524\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.6843 - acc: 0.5565 - val_loss: 0.6845 - val_acc: 0.5733\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.6807 - acc: 0.5728 - val_loss: 0.6818 - val_acc: 0.5851\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.6782 - acc: 0.5764 - val_loss: 0.6796 - val_acc: 0.5864\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.6750 - acc: 0.5869 - val_loss: 0.6777 - val_acc: 0.5851\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.6726 - acc: 0.5899 - val_loss: 0.6761 - val_acc: 0.5812\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.6709 - acc: 0.5938 - val_loss: 0.6746 - val_acc: 0.5785\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.6687 - acc: 0.5964 - val_loss: 0.6732 - val_acc: 0.5851\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.6669 - acc: 0.6010 - val_loss: 0.6721 - val_acc: 0.5838\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.6659 - acc: 0.6082 - val_loss: 0.6710 - val_acc: 0.5812\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.6643 - acc: 0.6118 - val_loss: 0.6700 - val_acc: 0.5812\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.6628 - acc: 0.6046 - val_loss: 0.6689 - val_acc: 0.5825\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.6614 - acc: 0.6131 - val_loss: 0.6681 - val_acc: 0.5864\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.6597 - acc: 0.6121 - val_loss: 0.6673 - val_acc: 0.5890\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.6583 - acc: 0.6105 - val_loss: 0.6666 - val_acc: 0.5877\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.6577 - acc: 0.6203 - val_loss: 0.6659 - val_acc: 0.5864\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.6569 - acc: 0.6196 - val_loss: 0.6653 - val_acc: 0.5864\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.6555 - acc: 0.6144 - val_loss: 0.6646 - val_acc: 0.5890\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.6537 - acc: 0.6223 - val_loss: 0.6640 - val_acc: 0.5864\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.6538 - acc: 0.6193 - val_loss: 0.6635 - val_acc: 0.5877\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.6520 - acc: 0.6259 - val_loss: 0.6629 - val_acc: 0.5916\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.6520 - acc: 0.6183 - val_loss: 0.6625 - val_acc: 0.5916\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.6501 - acc: 0.6213 - val_loss: 0.6620 - val_acc: 0.5929\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.6497 - acc: 0.6200 - val_loss: 0.6616 - val_acc: 0.5942\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.6491 - acc: 0.6272 - val_loss: 0.6611 - val_acc: 0.5942\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.6486 - acc: 0.6265 - val_loss: 0.6608 - val_acc: 0.5982\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.6477 - acc: 0.6291 - val_loss: 0.6605 - val_acc: 0.5982\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.6457 - acc: 0.6318 - val_loss: 0.6601 - val_acc: 0.5969\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.6456 - acc: 0.6301 - val_loss: 0.6598 - val_acc: 0.5969\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.6457 - acc: 0.6275 - val_loss: 0.6594 - val_acc: 0.5969\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.6453 - acc: 0.6285 - val_loss: 0.6591 - val_acc: 0.5969\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.6442 - acc: 0.6291 - val_loss: 0.6587 - val_acc: 0.6021\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.6436 - acc: 0.6321 - val_loss: 0.6584 - val_acc: 0.5995\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.6418 - acc: 0.6383 - val_loss: 0.6581 - val_acc: 0.6008\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.6419 - acc: 0.6324 - val_loss: 0.6577 - val_acc: 0.6021\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.6415 - acc: 0.6347 - val_loss: 0.6574 - val_acc: 0.6021\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.6413 - acc: 0.6367 - val_loss: 0.6571 - val_acc: 0.6008\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.6404 - acc: 0.6412 - val_loss: 0.6569 - val_acc: 0.5995\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.6403 - acc: 0.6344 - val_loss: 0.6566 - val_acc: 0.6008\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.6393 - acc: 0.6386 - val_loss: 0.6564 - val_acc: 0.6008\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.6381 - acc: 0.6399 - val_loss: 0.6562 - val_acc: 0.6021\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.6392 - acc: 0.6291 - val_loss: 0.6561 - val_acc: 0.6008\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.6373 - acc: 0.6393 - val_loss: 0.6559 - val_acc: 0.6008\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.6384 - acc: 0.6393 - val_loss: 0.6556 - val_acc: 0.6034\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.6375 - acc: 0.6403 - val_loss: 0.6554 - val_acc: 0.6060\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.6350 - acc: 0.6409 - val_loss: 0.6551 - val_acc: 0.6047\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.6356 - acc: 0.6435 - val_loss: 0.6550 - val_acc: 0.6060\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.6349 - acc: 0.6432 - val_loss: 0.6548 - val_acc: 0.6073\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f303f2ef0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model1.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=2,validation_data=(X_test,y_test))\n",
    "#Epoch 50/50\n",
    "# - 1s - loss: 0.6349 - acc: 0.6432 - val_loss: 0.6548 - val_acc: 0.6073\n",
    "#Wall time: 1min 7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = gru(timesteps, vocabsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3055 samples, validate on 764 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.6902 - acc: 0.5444 - val_loss: 0.6864 - val_acc: 0.6047\n",
      "Epoch 2/50\n",
      " - 2s - loss: 0.6863 - acc: 0.5804 - val_loss: 0.6835 - val_acc: 0.6021\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.6829 - acc: 0.5863 - val_loss: 0.6807 - val_acc: 0.5969\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.6797 - acc: 0.5957 - val_loss: 0.6783 - val_acc: 0.5995\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.6774 - acc: 0.6007 - val_loss: 0.6760 - val_acc: 0.6034\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.6746 - acc: 0.5967 - val_loss: 0.6738 - val_acc: 0.6073\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.6716 - acc: 0.6108 - val_loss: 0.6718 - val_acc: 0.6060\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.6693 - acc: 0.6085 - val_loss: 0.6700 - val_acc: 0.6073\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.6667 - acc: 0.6137 - val_loss: 0.6682 - val_acc: 0.6073\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.6646 - acc: 0.6193 - val_loss: 0.6667 - val_acc: 0.6099\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.6633 - acc: 0.6134 - val_loss: 0.6652 - val_acc: 0.6099\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.6611 - acc: 0.6164 - val_loss: 0.6639 - val_acc: 0.6113\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.6593 - acc: 0.6160 - val_loss: 0.6626 - val_acc: 0.6139\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.6576 - acc: 0.6193 - val_loss: 0.6614 - val_acc: 0.6191\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.6556 - acc: 0.6249 - val_loss: 0.6602 - val_acc: 0.6204\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.6543 - acc: 0.6255 - val_loss: 0.6592 - val_acc: 0.6191\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.6529 - acc: 0.6216 - val_loss: 0.6582 - val_acc: 0.6178\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.6516 - acc: 0.6265 - val_loss: 0.6572 - val_acc: 0.6165\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.6501 - acc: 0.6252 - val_loss: 0.6563 - val_acc: 0.6191\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.6489 - acc: 0.6301 - val_loss: 0.6555 - val_acc: 0.6204\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.6479 - acc: 0.6298 - val_loss: 0.6545 - val_acc: 0.6191\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.6460 - acc: 0.6308 - val_loss: 0.6536 - val_acc: 0.6217\n",
      "Epoch 23/50\n",
      " - 2s - loss: 0.6445 - acc: 0.6367 - val_loss: 0.6527 - val_acc: 0.6217\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.6432 - acc: 0.6347 - val_loss: 0.6518 - val_acc: 0.6257\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.6431 - acc: 0.6380 - val_loss: 0.6510 - val_acc: 0.6257\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.6410 - acc: 0.6383 - val_loss: 0.6503 - val_acc: 0.6270\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.6402 - acc: 0.6396 - val_loss: 0.6496 - val_acc: 0.6270\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.6388 - acc: 0.6396 - val_loss: 0.6489 - val_acc: 0.6283\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.6380 - acc: 0.6409 - val_loss: 0.6481 - val_acc: 0.6309\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.6363 - acc: 0.6426 - val_loss: 0.6475 - val_acc: 0.6322\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.6357 - acc: 0.6442 - val_loss: 0.6468 - val_acc: 0.6335\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.6346 - acc: 0.6478 - val_loss: 0.6461 - val_acc: 0.6335\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.6339 - acc: 0.6442 - val_loss: 0.6454 - val_acc: 0.6335\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.6327 - acc: 0.6491 - val_loss: 0.6449 - val_acc: 0.6296\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.6313 - acc: 0.6511 - val_loss: 0.6442 - val_acc: 0.6335\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.6309 - acc: 0.6465 - val_loss: 0.6436 - val_acc: 0.6335\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.6299 - acc: 0.6511 - val_loss: 0.6430 - val_acc: 0.6361\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.6297 - acc: 0.6524 - val_loss: 0.6424 - val_acc: 0.6361\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.6283 - acc: 0.6527 - val_loss: 0.6417 - val_acc: 0.6374\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.6274 - acc: 0.6514 - val_loss: 0.6412 - val_acc: 0.6387\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.6260 - acc: 0.6530 - val_loss: 0.6405 - val_acc: 0.6387\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.6257 - acc: 0.6527 - val_loss: 0.6401 - val_acc: 0.6401\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.6249 - acc: 0.6547 - val_loss: 0.6396 - val_acc: 0.6427\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.6246 - acc: 0.6570 - val_loss: 0.6392 - val_acc: 0.6387\n",
      "Epoch 45/50\n",
      " - 2s - loss: 0.6240 - acc: 0.6517 - val_loss: 0.6386 - val_acc: 0.6427\n",
      "Epoch 46/50\n",
      " - 2s - loss: 0.6219 - acc: 0.6612 - val_loss: 0.6381 - val_acc: 0.6414\n",
      "Epoch 47/50\n",
      " - 2s - loss: 0.6217 - acc: 0.6573 - val_loss: 0.6377 - val_acc: 0.6414\n",
      "Epoch 48/50\n",
      " - 2s - loss: 0.6211 - acc: 0.6628 - val_loss: 0.6372 - val_acc: 0.6414\n",
      "Epoch 49/50\n",
      " - 2s - loss: 0.6207 - acc: 0.6606 - val_loss: 0.6366 - val_acc: 0.6427\n",
      "Epoch 50/50\n",
      " - 2s - loss: 0.6202 - acc: 0.6625 - val_loss: 0.6362 - val_acc: 0.6427\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f442d7e10>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model2.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=2,validation_data=(X_test,y_test))\n",
    "#Epoch 50/50\n",
    "# - 2s - loss: 0.6202 - acc: 0.6625 - val_loss: 0.6362 - val_acc: 0.6427\n",
    "#Wall time: 1min 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = lstm(timesteps, vocabsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3055 samples, validate on 764 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.6066 - acc: 0.6727 - val_loss: 0.6365 - val_acc: 0.6492\n",
      "Epoch 2/50\n",
      " - 2s - loss: 0.6060 - acc: 0.6740 - val_loss: 0.6363 - val_acc: 0.6479\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.6038 - acc: 0.6812 - val_loss: 0.6360 - val_acc: 0.6492\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.6038 - acc: 0.6753 - val_loss: 0.6360 - val_acc: 0.6492\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.6032 - acc: 0.6769 - val_loss: 0.6358 - val_acc: 0.6492\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.6028 - acc: 0.6756 - val_loss: 0.6355 - val_acc: 0.6505\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.6008 - acc: 0.6795 - val_loss: 0.6354 - val_acc: 0.6518\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.6009 - acc: 0.6750 - val_loss: 0.6356 - val_acc: 0.6466\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.5997 - acc: 0.6812 - val_loss: 0.6358 - val_acc: 0.6479\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.6005 - acc: 0.6815 - val_loss: 0.6351 - val_acc: 0.6531\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.5995 - acc: 0.6809 - val_loss: 0.6355 - val_acc: 0.6479\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.5990 - acc: 0.6812 - val_loss: 0.6352 - val_acc: 0.6453\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.5986 - acc: 0.6822 - val_loss: 0.6349 - val_acc: 0.6466\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.5967 - acc: 0.6799 - val_loss: 0.6349 - val_acc: 0.6466\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.5969 - acc: 0.6828 - val_loss: 0.6352 - val_acc: 0.6453\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.5964 - acc: 0.6802 - val_loss: 0.6342 - val_acc: 0.6531\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.5965 - acc: 0.6848 - val_loss: 0.6341 - val_acc: 0.6531\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.5951 - acc: 0.6809 - val_loss: 0.6349 - val_acc: 0.6466\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.5953 - acc: 0.6867 - val_loss: 0.6346 - val_acc: 0.6466\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.5950 - acc: 0.6815 - val_loss: 0.6343 - val_acc: 0.6518\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.5943 - acc: 0.6799 - val_loss: 0.6344 - val_acc: 0.6466\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.5949 - acc: 0.6835 - val_loss: 0.6343 - val_acc: 0.6453\n",
      "Epoch 23/50\n",
      " - 2s - loss: 0.5939 - acc: 0.6920 - val_loss: 0.6340 - val_acc: 0.6479\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.5916 - acc: 0.6861 - val_loss: 0.6339 - val_acc: 0.6466\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.5926 - acc: 0.6900 - val_loss: 0.6338 - val_acc: 0.6492\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.5919 - acc: 0.6913 - val_loss: 0.6338 - val_acc: 0.6466\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.5903 - acc: 0.6881 - val_loss: 0.6334 - val_acc: 0.6479\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.5897 - acc: 0.6887 - val_loss: 0.6336 - val_acc: 0.6466\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.5901 - acc: 0.6871 - val_loss: 0.6339 - val_acc: 0.6466\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.5896 - acc: 0.6917 - val_loss: 0.6341 - val_acc: 0.6440\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.5900 - acc: 0.6887 - val_loss: 0.6333 - val_acc: 0.6479\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.5885 - acc: 0.6894 - val_loss: 0.6334 - val_acc: 0.6466\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.5881 - acc: 0.6864 - val_loss: 0.6338 - val_acc: 0.6466\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.5886 - acc: 0.6907 - val_loss: 0.6335 - val_acc: 0.6466\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.5876 - acc: 0.6887 - val_loss: 0.6336 - val_acc: 0.6466\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.5883 - acc: 0.6943 - val_loss: 0.6328 - val_acc: 0.6479\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.5857 - acc: 0.6884 - val_loss: 0.6327 - val_acc: 0.6466\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.5868 - acc: 0.6913 - val_loss: 0.6326 - val_acc: 0.6479\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.5853 - acc: 0.6946 - val_loss: 0.6327 - val_acc: 0.6466\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.5857 - acc: 0.6926 - val_loss: 0.6331 - val_acc: 0.6453\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.5842 - acc: 0.6972 - val_loss: 0.6339 - val_acc: 0.6453\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.5853 - acc: 0.6890 - val_loss: 0.6329 - val_acc: 0.6453\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.5849 - acc: 0.6966 - val_loss: 0.6327 - val_acc: 0.6466\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.5842 - acc: 0.6953 - val_loss: 0.6326 - val_acc: 0.6466\n",
      "Epoch 45/50\n",
      " - 2s - loss: 0.5836 - acc: 0.6943 - val_loss: 0.6322 - val_acc: 0.6479\n",
      "Epoch 46/50\n",
      " - 2s - loss: 0.5820 - acc: 0.6979 - val_loss: 0.6321 - val_acc: 0.6479\n",
      "Epoch 47/50\n",
      " - 2s - loss: 0.5830 - acc: 0.6943 - val_loss: 0.6324 - val_acc: 0.6453\n",
      "Epoch 48/50\n",
      " - 2s - loss: 0.5832 - acc: 0.6959 - val_loss: 0.6329 - val_acc: 0.6466\n",
      "Epoch 49/50\n",
      " - 2s - loss: 0.5817 - acc: 0.6992 - val_loss: 0.6330 - val_acc: 0.6479\n",
      "Epoch 50/50\n",
      " - 2s - loss: 0.5809 - acc: 0.7011 - val_loss: 0.6324 - val_acc: 0.6466\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f2e5212e8>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model3.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=2,validation_data=(X_test,y_test))\n",
    "#Epoch 50/50\n",
    "# - 2s - loss: 0.5809 - acc: 0.7011 - val_loss: 0.6324 - val_acc: 0.6466\n",
    "#Wall time: 1min 27s#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "0c8c52d1bb614fb7b33eb92b87361120": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ffbacb111da34a46b7f4043da019056b": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
